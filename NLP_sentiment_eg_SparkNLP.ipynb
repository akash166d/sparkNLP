{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_sentiment_eg_SparkNLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMZS+HOWKh92x6mRsrfJChr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akash166d/sparkNLP/blob/master/NLP_sentiment_eg_SparkNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBmc0480QLzB",
        "colab_type": "text"
      },
      "source": [
        "# Install Package/Lib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwc2OqTH16VJ",
        "colab_type": "text"
      },
      "source": [
        "This is required to ensure the ubuntu related dependencies are up to date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQwcI3O3KCty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cec1a608-7aaa-4d81-b0f0-674c872bec4c"
      },
      "source": [
        "! sudo apt-get update --fix-missing\n",
        "! sudo apt-get upgrade --fix-missing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [2 InRelease 3,626 B/3,626 B 100\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r                                                                               \rHit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [4 InRelease 14.2 kB/88.7 kB 16%] [Waiting for headers\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rGet:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rGet:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Ign:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [255 kB]\n",
            "Get:15 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,857 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [9,558 B]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [882 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,336 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,038 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [116 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,413 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [27.1 kB]\n",
            "Get:23 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [896 kB]\n",
            "Fetched 8,102 kB in 3s (3,238 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Calculating upgrade... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following packages have been kept back:\n",
            "  libcublas-dev libcublas10 libcudnn7 libcudnn7-dev libnccl-dev libnccl2\n",
            "  r-cran-tidyr\n",
            "The following packages will be upgraded:\n",
            "  base-files binutils binutils-common binutils-x86-64-linux-gnu bsdutils\n",
            "  cuda-compat-10-1 e2fsprogs fdisk kmod libbinutils libblkid1 libc-bin\n",
            "  libcom-err2 libext2fs2 libfdisk1 libgcrypt20 libgnutls30 libkmod2\n",
            "  libldap-2.4-2 libldap-common libmount1 libnss3 libpam-systemd libpulse0\n",
            "  libsasl2-2 libsasl2-modules-db libseccomp2 libsmartcols1 libsqlite3-0 libss2\n",
            "  libssh-gcrypt-4 libsystemd0 libudev1 linux-libc-dev module-init-tools mount\n",
            "  openssl python3-software-properties r-cran-dplyr r-cran-dt r-cran-fs\n",
            "  r-cran-ps software-properties-common systemd systemd-sysv udev util-linux\n",
            "47 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 23.1 MB of archives.\n",
            "After this operation, 315 kB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-compat-10-1 418.152.00-1 [5,246 kB]\n",
            "Get:2 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 r-cran-dplyr amd64 1.0.1-1cran1.1804.0 [1,040 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 base-files amd64 10.1ubuntu2.9 [59.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 bsdutils amd64 1:2.31.1-0.4ubuntu3.6 [60.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libext2fs2 amd64 1.44.1-1ubuntu1.3 [157 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 e2fsprogs amd64 1.44.1-1ubuntu1.3 [391 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libblkid1 amd64 2.31.1-0.4ubuntu3.6 [124 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libfdisk1 amd64 2.31.1-0.4ubuntu3.6 [164 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmount1 amd64 2.31.1-0.4ubuntu3.6 [136 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsmartcols1 amd64 2.31.1-0.4ubuntu3.6 [83.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 fdisk amd64 2.31.1-0.4ubuntu3.6 [108 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 util-linux amd64 2.31.1-0.4ubuntu3.6 [903 kB]\n",
            "Get:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 r-cran-dt all 0.15-1cran1.1804.0 [1,199 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libc-bin amd64 2.27-3ubuntu1.2 [637 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 systemd-sysv amd64 237-3ubuntu10.42 [15.2 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpam-systemd amd64 237-3ubuntu10.42 [107 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsystemd0 amd64 237-3ubuntu10.42 [208 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 systemd amd64 237-3ubuntu10.42 [2,914 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 udev amd64 237-3ubuntu10.42 [1,102 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libudev1 amd64 237-3ubuntu10.42 [57.4 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 kmod amd64 24-1ubuntu3.5 [88.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkmod2 amd64 24-1ubuntu3.5 [40.2 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 mount amd64 2.31.1-0.4ubuntu3.6 [107 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcom-err2 amd64 1.44.1-1ubuntu1.3 [8,848 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgcrypt20 amd64 1.8.1-4ubuntu1.2 [417 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libss2 amd64 1.44.1-1ubuntu1.3 [11.1 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgnutls30 amd64 3.5.18-1ubuntu1.4 [645 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libseccomp2 amd64 2.4.3-1ubuntu3.18.04.3 [42.0 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsqlite3-0 amd64 3.22.0-1ubuntu0.4 [499 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssl amd64 1.1.1-1ubuntu2.1~18.04.6 [614 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.30-21ubuntu1~18.04.4 [1,839 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 binutils-common amd64 2.30-21ubuntu1~18.04.4 [196 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 binutils amd64 2.30-21ubuntu1~18.04.4 [3,392 B]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libbinutils amd64 2.30-21ubuntu1~18.04.4 [488 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsasl2-modules-db amd64 2.1.27~101-g0780600+dfsg-3ubuntu2.1 [14.8 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsasl2-2 amd64 2.1.27~101-g0780600+dfsg-3ubuntu2.1 [49.2 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libldap-common all 2.4.45+dfsg-1ubuntu1.6 [17.0 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libldap-2.4-2 amd64 2.4.45+dfsg-1ubuntu1.6 [155 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnss3 amd64 2:3.35-2ubuntu2.11 [1,221 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse0 amd64 1:11.1-1ubuntu7.10 [266 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libssh-gcrypt-4 amd64 0.8.0~20170825.94fa1e38-1ubuntu0.7 [172 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 linux-libc-dev amd64 4.15.0-112.113 [982 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 module-init-tools all 24-1ubuntu3.5 [2,516 B]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 software-properties-common all 0.96.24.32.14 [10.1 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-software-properties all 0.96.24.32.14 [23.9 kB]\n",
            "Get:46 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 r-cran-fs amd64 1.5.0-1cran1.1804.0 [254 kB]\n",
            "Get:47 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 r-cran-ps amd64 1.3.4-1cran1.1804.0 [206 kB]\n",
            "Fetched 23.1 MB in 3s (8,793 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 47.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../base-files_10.1ubuntu2.9_amd64.deb ...\n",
            "Unpacking base-files (10.1ubuntu2.9) over (10.1ubuntu2.7) ...\n",
            "Setting up base-files (10.1ubuntu2.9) ...\n",
            "Installing new version of config file /etc/issue ...\n",
            "Installing new version of config file /etc/issue.net ...\n",
            "Installing new version of config file /etc/lsb-release ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../bsdutils_1%3a2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking bsdutils (1:2.31.1-0.4ubuntu3.6) over (1:2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up bsdutils (1:2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libext2fs2_1.44.1-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libext2fs2:amd64 (1.44.1-1ubuntu1.3) over (1.44.1-1ubuntu1.2) ...\n",
            "Setting up libext2fs2:amd64 (1.44.1-1ubuntu1.3) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../e2fsprogs_1.44.1-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking e2fsprogs (1.44.1-1ubuntu1.3) over (1.44.1-1ubuntu1.2) ...\n",
            "Setting up e2fsprogs (1.44.1-1ubuntu1.3) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libblkid1_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking libblkid1:amd64 (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up libblkid1:amd64 (2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libfdisk1_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking libfdisk1:amd64 (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up libfdisk1:amd64 (2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libmount1_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking libmount1:amd64 (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up libmount1:amd64 (2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libsmartcols1_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking libsmartcols1:amd64 (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up libsmartcols1:amd64 (2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../fdisk_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking fdisk (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up fdisk (2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../util-linux_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking util-linux (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Setting up util-linux (2.31.1-0.4ubuntu3.6) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-bin_2.27-3ubuntu1.2_amd64.deb ...\n",
            "Unpacking libc-bin (2.27-3ubuntu1.2) over (2.27-3ubuntu1) ...\n",
            "Setting up libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../systemd-sysv_237-3ubuntu10.42_amd64.deb ...\n",
            "Unpacking systemd-sysv (237-3ubuntu10.42) over (237-3ubuntu10.41) ...\n",
            "Preparing to unpack .../libpam-systemd_237-3ubuntu10.42_amd64.deb ...\n",
            "Unpacking libpam-systemd:amd64 (237-3ubuntu10.42) over (237-3ubuntu10.41) ...\n",
            "Preparing to unpack .../libsystemd0_237-3ubuntu10.42_amd64.deb ...\n",
            "Unpacking libsystemd0:amd64 (237-3ubuntu10.42) over (237-3ubuntu10.41) ...\n",
            "Setting up libsystemd0:amd64 (237-3ubuntu10.42) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../systemd_237-3ubuntu10.42_amd64.deb ...\n",
            "Unpacking systemd (237-3ubuntu10.42) over (237-3ubuntu10.41) ...\n",
            "Preparing to unpack .../udev_237-3ubuntu10.42_amd64.deb ...\n",
            "Unpacking udev (237-3ubuntu10.42) over (237-3ubuntu10.41) ...\n",
            "Preparing to unpack .../libudev1_237-3ubuntu10.42_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (237-3ubuntu10.42) over (237-3ubuntu10.41) ...\n",
            "Setting up libudev1:amd64 (237-3ubuntu10.42) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../kmod_24-1ubuntu3.5_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu3.5) over (24-1ubuntu3.4) ...\n",
            "Preparing to unpack .../libkmod2_24-1ubuntu3.5_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu3.5) over (24-1ubuntu3.4) ...\n",
            "Preparing to unpack .../mount_2.31.1-0.4ubuntu3.6_amd64.deb ...\n",
            "Unpacking mount (2.31.1-0.4ubuntu3.6) over (2.31.1-0.4ubuntu3.4) ...\n",
            "Preparing to unpack .../libcom-err2_1.44.1-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libcom-err2:amd64 (1.44.1-1ubuntu1.3) over (1.44.1-1ubuntu1.2) ...\n",
            "Setting up libcom-err2:amd64 (1.44.1-1ubuntu1.3) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libgcrypt20_1.8.1-4ubuntu1.2_amd64.deb ...\n",
            "Unpacking libgcrypt20:amd64 (1.8.1-4ubuntu1.2) over (1.8.1-4ubuntu1.1) ...\n",
            "Setting up libgcrypt20:amd64 (1.8.1-4ubuntu1.2) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libss2_1.44.1-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libss2:amd64 (1.44.1-1ubuntu1.3) over (1.44.1-1ubuntu1.2) ...\n",
            "Setting up libss2:amd64 (1.44.1-1ubuntu1.3) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libgnutls30_3.5.18-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking libgnutls30:amd64 (3.5.18-1ubuntu1.4) over (3.5.18-1ubuntu1.1) ...\n",
            "Setting up libgnutls30:amd64 (3.5.18-1ubuntu1.4) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libseccomp2_2.4.3-1ubuntu3.18.04.3_amd64.deb ...\n",
            "Unpacking libseccomp2:amd64 (2.4.3-1ubuntu3.18.04.3) over (2.4.1-0ubuntu0.18.04.2) ...\n",
            "Setting up libseccomp2:amd64 (2.4.3-1ubuntu3.18.04.3) ...\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libsqlite3-0_3.22.0-1ubuntu0.4_amd64.deb ...\n",
            "Unpacking libsqlite3-0:amd64 (3.22.0-1ubuntu0.4) over (3.22.0-1ubuntu0.1) ...\n",
            "Preparing to unpack .../01-openssl_1.1.1-1ubuntu2.1~18.04.6_amd64.deb ...\n",
            "Unpacking openssl (1.1.1-1ubuntu2.1~18.04.6) over (1.1.1-1ubuntu2.1~18.04.5) ...\n",
            "Preparing to unpack .../02-binutils-x86-64-linux-gnu_2.30-21ubuntu1~18.04.4_amd64.deb ...\n",
            "Unpacking binutils-x86-64-linux-gnu (2.30-21ubuntu1~18.04.4) over (2.30-21ubuntu1~18.04.2) ...\n",
            "Preparing to unpack .../03-binutils-common_2.30-21ubuntu1~18.04.4_amd64.deb ...\n",
            "Unpacking binutils-common:amd64 (2.30-21ubuntu1~18.04.4) over (2.30-21ubuntu1~18.04.2) ...\n",
            "Preparing to unpack .../04-binutils_2.30-21ubuntu1~18.04.4_amd64.deb ...\n",
            "Unpacking binutils (2.30-21ubuntu1~18.04.4) over (2.30-21ubuntu1~18.04.2) ...\n",
            "Preparing to unpack .../05-libbinutils_2.30-21ubuntu1~18.04.4_amd64.deb ...\n",
            "Unpacking libbinutils:amd64 (2.30-21ubuntu1~18.04.4) over (2.30-21ubuntu1~18.04.2) ...\n",
            "Preparing to unpack .../06-cuda-compat-10-1_418.152.00-1_amd64.deb ...\n",
            "Unpacking cuda-compat-10-1 (418.152.00-1) over (418.87.01-1) ...\n",
            "Preparing to unpack .../07-libsasl2-modules-db_2.1.27~101-g0780600+dfsg-3ubuntu2.1_amd64.deb ...\n",
            "Unpacking libsasl2-modules-db:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.1) over (2.1.27~101-g0780600+dfsg-3ubuntu2) ...\n",
            "Preparing to unpack .../08-libsasl2-2_2.1.27~101-g0780600+dfsg-3ubuntu2.1_amd64.deb ...\n",
            "Unpacking libsasl2-2:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.1) over (2.1.27~101-g0780600+dfsg-3ubuntu2) ...\n",
            "Preparing to unpack .../09-libldap-common_2.4.45+dfsg-1ubuntu1.6_all.deb ...\n",
            "Unpacking libldap-common (2.4.45+dfsg-1ubuntu1.6) over (2.4.45+dfsg-1ubuntu1.4) ...\n",
            "Preparing to unpack .../10-libldap-2.4-2_2.4.45+dfsg-1ubuntu1.6_amd64.deb ...\n",
            "Unpacking libldap-2.4-2:amd64 (2.4.45+dfsg-1ubuntu1.6) over (2.4.45+dfsg-1ubuntu1.4) ...\n",
            "Preparing to unpack .../11-libnss3_2%3a3.35-2ubuntu2.11_amd64.deb ...\n",
            "Unpacking libnss3:amd64 (2:3.35-2ubuntu2.11) over (2:3.35-2ubuntu2.9) ...\n",
            "Preparing to unpack .../12-libpulse0_1%3a11.1-1ubuntu7.10_amd64.deb ...\n",
            "Unpacking libpulse0:amd64 (1:11.1-1ubuntu7.10) over (1:11.1-1ubuntu7.9) ...\n",
            "Preparing to unpack .../13-libssh-gcrypt-4_0.8.0~20170825.94fa1e38-1ubuntu0.7_amd64.deb ...\n",
            "Unpacking libssh-gcrypt-4:amd64 (0.8.0~20170825.94fa1e38-1ubuntu0.7) over (0.8.0~20170825.94fa1e38-1ubuntu0.6) ...\n",
            "Preparing to unpack .../14-linux-libc-dev_4.15.0-112.113_amd64.deb ...\n",
            "Unpacking linux-libc-dev:amd64 (4.15.0-112.113) over (4.15.0-72.81) ...\n",
            "Preparing to unpack .../15-module-init-tools_24-1ubuntu3.5_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu3.5) over (24-1ubuntu3.4) ...\n",
            "Preparing to unpack .../16-software-properties-common_0.96.24.32.14_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.32.14) over (0.96.24.32.13) ...\n",
            "Preparing to unpack .../17-python3-software-properties_0.96.24.32.14_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.32.14) over (0.96.24.32.13) ...\n",
            "Preparing to unpack .../18-r-cran-dplyr_1.0.1-1cran1.1804.0_amd64.deb ...\n",
            "Unpacking r-cran-dplyr (1.0.1-1cran1.1804.0) over (1.0.0-1cran1.1804.0) ...\n",
            "Preparing to unpack .../19-r-cran-dt_0.15-1cran1.1804.0_all.deb ...\n",
            "Unpacking r-cran-dt (0.15-1cran1.1804.0) over (0.14-1cran1.1804.0) ...\n",
            "Preparing to unpack .../20-r-cran-fs_1.5.0-1cran1.1804.0_amd64.deb ...\n",
            "Unpacking r-cran-fs (1.5.0-1cran1.1804.0) over (1.4.2-1cran1.1804.0) ...\n",
            "Preparing to unpack .../21-r-cran-ps_1.3.4-1cran1.1804.0_amd64.deb ...\n",
            "Unpacking r-cran-ps (1.3.4-1cran1.1804.0) over (1.3.3-1cran1.1804.0) ...\n",
            "Setting up r-cran-ps (1.3.4-1cran1.1804.0) ...\n",
            "Setting up libldap-common (2.4.45+dfsg-1ubuntu1.6) ...\n",
            "Setting up cuda-compat-10-1 (418.152.00-1) ...\n",
            "Setting up libssh-gcrypt-4:amd64 (0.8.0~20170825.94fa1e38-1ubuntu0.7) ...\n",
            "Setting up libsasl2-modules-db:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.1) ...\n",
            "Setting up linux-libc-dev:amd64 (4.15.0-112.113) ...\n",
            "Setting up mount (2.31.1-0.4ubuntu3.6) ...\n",
            "Setting up libsasl2-2:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu3.5) ...\n",
            "Setting up libpulse0:amd64 (1:11.1-1ubuntu7.10) ...\n",
            "Setting up binutils-common:amd64 (2.30-21ubuntu1~18.04.4) ...\n",
            "Setting up r-cran-dt (0.15-1cran1.1804.0) ...\n",
            "Setting up udev (237-3ubuntu10.42) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of restart.\n",
            "Setting up libldap-2.4-2:amd64 (2.4.45+dfsg-1ubuntu1.6) ...\n",
            "Setting up r-cran-fs (1.5.0-1cran1.1804.0) ...\n",
            "Setting up systemd (237-3ubuntu10.42) ...\n",
            "Setting up r-cran-dplyr (1.0.1-1cran1.1804.0) ...\n",
            "Setting up openssl (1.1.1-1ubuntu2.1~18.04.6) ...\n",
            "Setting up libsqlite3-0:amd64 (3.22.0-1ubuntu0.4) ...\n",
            "Setting up python3-software-properties (0.96.24.32.14) ...\n",
            "Setting up software-properties-common (0.96.24.32.14) ...\n",
            "Setting up kmod (24-1ubuntu3.5) ...\n",
            "Setting up libbinutils:amd64 (2.30-21ubuntu1~18.04.4) ...\n",
            "Setting up systemd-sysv (237-3ubuntu10.42) ...\n",
            "Setting up libnss3:amd64 (2:3.35-2ubuntu2.11) ...\n",
            "Setting up module-init-tools (24-1ubuntu3.5) ...\n",
            "Setting up binutils-x86-64-linux-gnu (2.30-21ubuntu1~18.04.4) ...\n",
            "Setting up libpam-systemd:amd64 (237-3ubuntu10.42) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up binutils (2.30-21ubuntu1~18.04.4) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for dbus (1.12.2-1ubuntu1.2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q2etGjaMgCG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "936bac08-90e8-46bb-ed03-11d1bf17243e"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed -q pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed -q spark-nlp==2.5.4\n",
        "\n",
        "! pip install --user -U nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_265\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_265-8u265-b01-0ubuntu2~18.04-b01)\n",
            "OpenJDK 64-Bit Server VM (build 25.265-b01, mixed mode)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 52kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 43.1MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hCollecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.41.1)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434674 sha256=dfa509c009c6abd1ac4a464b7fe76d736d43b2813f043300555749c71156befc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "\u001b[33m  WARNING: The script nltk is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed nltk-3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2RzyRTnNGjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cc6823c2-b4ed-4099-a094-b465fefed991"
      },
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version; \", spark.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version:  2.5.4\n",
            "Apache Spark version;  2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0yrTMJaQWqz",
        "colab_type": "text"
      },
      "source": [
        "# Mount Drive and read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLD74i7zONK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "d222963d-8cc8-4f3d-a728-142c5fd75497"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS0s8wYL25E9",
        "colab_type": "text"
      },
      "source": [
        "Some of the sparkNLP annotators were having trouble reading spaces in path, hence used symbolic link to replace the path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPSDHjKbOmpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ln -s \"/content/drive/My Drive\" \"/content/MyDrive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7sjN-NzO1tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "song_data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/content/drive/My Drive/SparkNLP/song_2k.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p--pxgIPSQz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "a296c519-b64c-4ff9-ef29-9e4c0ad8e30a"
      },
      "source": [
        "from pyspark.sql import functions as F\n",
        "song_data = song_data.select(['Key', 'Lyric', 'Genre']).withColumnRenamed('Lyric','text')\n",
        "\n",
        "# train, test = trainDataset.randomSplit(weights=[0.5, 0.5], seed=123)\n",
        "song_data = song_data.limit(999)\n",
        "print(song_data.count())\n",
        "\n",
        "song_data = song_data.filter(song_data.text != '')\n",
        "print(song_data.count())\n",
        "song_data = song_data.filter((song_data.Genre == 'Rock') | (song_data.Genre == 'Hip Hop') | (song_data.Genre == 'Pop')  )\n",
        "# song_data = song_data.filter(song_data.Genre != '')\n",
        "print(song_data.count())\n",
        "# song_data = song_data.filter(song_data.text != ' ')\n",
        "# print(song_data.count())\n",
        "# song_data = song_data.filter(song_data.Genre != ' ')\n",
        "# print(song_data.count())\n",
        "song_data.na.drop(subset=[\"text\"])\n",
        "print(song_data.count())\n",
        "song_data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "999\n",
            "999\n",
            "915\n",
            "915\n",
            "+--------------------+--------------------+-------+\n",
            "|                 Key|                text|  Genre|\n",
            "+--------------------+--------------------+-------+\n",
            "|10000 maniacs_Mor...|I could feel at t...|   Rock|\n",
            "|10000 maniacs_Bec...|Take me now, baby...|   Rock|\n",
            "|jamiroquai_Rock D...|And it's coming a...|    Pop|\n",
            "|10000 maniacs_The...|These are. These ...|   Rock|\n",
            "|10000 maniacs_Eve...|Trudging slowly o...|   Rock|\n",
            "|10000 maniacs_Don...|Don't talk, I wil...|   Rock|\n",
            "|black veil brides...|Have we begun to ...|   Rock|\n",
            "|lynyrd skynyrd_I ...|Ain't no need to ...|   Rock|\n",
            "|10000 maniacs_Acr...|Well they left th...|   Rock|\n",
            "|10000 maniacs_Pla...|[ music: Dennis D...|   Rock|\n",
            "|10000 maniacs_Rai...|On bended kneeI'v...|   Rock|\n",
            "|twista_Back 2 School|[Tung Twista]. ba...|Hip Hop|\n",
            "|10000 maniacs_Ant...|For whom do the b...|   Rock|\n",
            "|10000 maniacs_All...|She walks alone o...|   Rock|\n",
            "|10000 maniacs_Bac...|Jenny. Jenny you ...|   Rock|\n",
            "|cyndi lauper_True...|You with the sad ...|    Pop|\n",
            "|10000 maniacs_A R...|You were looking ...|   Rock|\n",
            "|rick astley_She M...|She makes me more...|    Pop|\n",
            "|steve earle_Nothi...|I'm the keeper of...|   Rock|\n",
            "|10000 maniacs_Mad...|\"the legs of Madd...|   Rock|\n",
            "+--------------------+--------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyXMOyWZP4Xb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e56d32b-c945-4093-ac00-b12614bf8874"
      },
      "source": [
        "print(type(song_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPdwWmc3iPz",
        "colab_type": "text"
      },
      "source": [
        "# Package Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeBx3-P6P6Q9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f9d1a0f2-2717-47e8-fbd4-1c2b64435801"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from pyspark.sql import functions as F"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH_L4yv9Qc_-",
        "colab_type": "text"
      },
      "source": [
        "# Vocab Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiHyoUe_33ci",
        "colab_type": "text"
      },
      "source": [
        "Basic Data cleaning for NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atU2csZwRIJD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "044200ee-cab2-46d0-b341-10e11b69fbfd"
      },
      "source": [
        "assembler = DocumentAssembler().setInputCol('text').setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector().setInputCols([\"document\"]).setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer().setInputCols(['document']).setOutputCol('token')#.setTargetPattern('/\\b(\\?You were looking)\\b/')#.setExceptionsPath('/content/MyDrive/SparkNLP/entities.txt')\n",
        "\n",
        "spell_chk = NorvigSweetingModel().pretrained().setInputCols(['token']).setOutputCol('corrected')\n",
        "\n",
        "lemmatizer = LemmatizerModel().pretrained().setInputCols(['corrected']).setOutputCol('lemma')\n",
        "\n",
        "normalizer = Normalizer().setInputCols(['lemma']).setOutputCol('normalized').setLowercase(True)\n",
        "\n",
        "stop_wrd = list( stopwords.words('english'))\n",
        "\n",
        "stop_words_cleaner = StopWordsCleaner().setInputCols([\"normalized\"]).setOutputCol(\"cleanTokens\").setCaseSensitive(False).setStopWords(stop_wrd)\n",
        "\n",
        "# token_assembler = TokenAssembler().setInputCols([\"cleanTokens\"]).setOutputCol(\"assembled\")\n",
        "\n",
        "finisher = Finisher().setInputCols(['cleanTokens']).setOutputCols(['cleanTokens']).setOutputAsArray(True)#.setValueSplitSymbol(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spellcheck_norvig download started this may take some time.\n",
            "Approximate size to download 4.2 MB\n",
            "[OK!]\n",
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfOlqRGP4qnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "cb0d2fdf-4fd0-4f02-a9dc-e098d8e2cc67"
      },
      "source": [
        "pipeline_bow = Pipeline().setStages([\n",
        "    assembler, tokenizer, spell_chk , \n",
        "    lemmatizer, normalizer,stop_words_cleaner,finisher\n",
        "])\n",
        "model_trans_tfIdf = pipeline_bow.fit(song_data)\n",
        "model_trans_tfIdf =  model_trans_tfIdf.transform(song_data)\n",
        "model_trans_tfIdf.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-------+--------------------+\n",
            "|                 Key|                text|  Genre|         cleanTokens|\n",
            "+--------------------+--------------------+-------+--------------------+\n",
            "|10000 maniacs_Mor...|I could feel at t...|   Rock|[could, feel, tim...|\n",
            "|10000 maniacs_Bec...|Take me now, baby...|   Rock|[take, baby, hold...|\n",
            "|jamiroquai_Rock D...|And it's coming a...|    Pop|[come, baby, yeah...|\n",
            "|10000 maniacs_The...|These are. These ...|   Rock|[day, youll, reme...|\n",
            "|10000 maniacs_Eve...|Trudging slowly o...|   Rock|[grudge, slowly, ...|\n",
            "|10000 maniacs_Don...|Don't talk, I wil...|   Rock|[donut, talk, lis...|\n",
            "|black veil brides...|Have we begun to ...|   Rock|[begin, drift, aw...|\n",
            "|lynyrd skynyrd_I ...|Ain't no need to ...|   Rock|[aint, need, worr...|\n",
            "|10000 maniacs_Acr...|Well they left th...|   Rock|[well, leave, mor...|\n",
            "|10000 maniacs_Pla...|[ music: Dennis D...|   Rock|[music, dennis, d...|\n",
            "|10000 maniacs_Rai...|On bended kneeI'v...|   Rock|[bend, kneeive, l...|\n",
            "|twista_Back 2 School|[Tung Twista]. ba...|Hip Hop|[tung, twista, ba...|\n",
            "|10000 maniacs_Ant...|For whom do the b...|   Rock|[bell, toll, sent...|\n",
            "|10000 maniacs_All...|She walks alone o...|   Rock|[walk, alone, bri...|\n",
            "|10000 maniacs_Bac...|Jenny. Jenny you ...|   Rock|[jenny, jenny, do...|\n",
            "|cyndi lauper_True...|You with the sad ...|    Pop|[sad, eye, donut,...|\n",
            "|10000 maniacs_A R...|You were looking ...|   Rock|[look, away, west...|\n",
            "|rick astley_She M...|She makes me more...|    Pop|[make, could, eve...|\n",
            "|steve earle_Nothi...|I'm the keeper of...|   Rock|[im, keeper, hear...|\n",
            "|10000 maniacs_Mad...|\"the legs of Madd...|   Rock|[leg, maddox, kit...|\n",
            "+--------------------+--------------------+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWrdAicAzKvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "f9940e92-1f47-4161-fe3f-6bf936d37c5c"
      },
      "source": [
        "#convert list to sentence\n",
        "from pyspark.sql.functions import udf, explode\n",
        "from pyspark.sql.types import *\n",
        "@udf( StringType())\n",
        "def get_sentence(word_in):\n",
        "    return \" \".join(str(item) for item in word_in)\n",
        "\n",
        "# udf_to_doc = udf(get_sentence, StringType())\n",
        "\n",
        "df_cleanToken = model_trans_tfIdf.select('Key','Genre', get_sentence(F.col('cleanTokens')).alias('text'))\n",
        "# bow_top_embd = bow_top_embd.filter((F.col('doc') != '') | F.col('doc') != ' ')\n",
        "df_cleanToken.na.drop(subset=[\"text\"])\n",
        "from pyspark.sql.functions import trim\n",
        "df_cleanToken = df_cleanToken.withColumn(\"text\", trim(df_cleanToken.text))\n",
        "# bow_top_embd.filter(!(F.col('doc') == ' ')).show()\n",
        "df_cleanToken.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------+--------------------+\n",
            "|                 Key|  Genre|                text|\n",
            "+--------------------+-------+--------------------+\n",
            "|10000 maniacs_Mor...|   Rock|could feel time w...|\n",
            "|10000 maniacs_Bec...|   Rock|take baby hold cl...|\n",
            "|jamiroquai_Rock D...|    Pop|come baby yeah co...|\n",
            "|10000 maniacs_The...|   Rock|day youll remembe...|\n",
            "|10000 maniacs_Eve...|   Rock|grudge slowly wet...|\n",
            "|10000 maniacs_Don...|   Rock|donut talk listen...|\n",
            "|black veil brides...|   Rock|begin drift away ...|\n",
            "|lynyrd skynyrd_I ...|   Rock|aint need worry a...|\n",
            "|10000 maniacs_Acr...|   Rock|well leave mornin...|\n",
            "|10000 maniacs_Pla...|   Rock|music dennis drew...|\n",
            "|10000 maniacs_Rai...|   Rock|bend kneeive look...|\n",
            "|twista_Back 2 School|Hip Hop|tung twista back ...|\n",
            "|10000 maniacs_Ant...|   Rock|bell toll sentenc...|\n",
            "|10000 maniacs_All...|   Rock|walk alone brick ...|\n",
            "|10000 maniacs_Bac...|   Rock|jenny jenny dont ...|\n",
            "|cyndi lauper_True...|    Pop|sad eye donut dis...|\n",
            "|10000 maniacs_A R...|   Rock|look away western...|\n",
            "|rick astley_She M...|    Pop|make could ever m...|\n",
            "|steve earle_Nothi...|   Rock|im keeper heart k...|\n",
            "|10000 maniacs_Mad...|   Rock|leg maddox kitche...|\n",
            "+--------------------+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-KZPyPADWga",
        "colab_type": "text"
      },
      "source": [
        "# Unsupervised Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba8fhOArDaHZ",
        "colab_type": "text"
      },
      "source": [
        "## Analyze_sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0-Acu2Yv9fV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "7b282967-e24f-452b-b0da-1beb0e73d3d8"
      },
      "source": [
        "pipeline = PretrainedPipeline(\"analyze_sentiment\", lang=\"en\")\n",
        "# mod_sent = pipeline.fit(model_trans_tfIdf)\n",
        "sent_df = pipeline.transform(df_cleanToken)\n",
        "sent_df = sent_df.select('text','sentiment.result' ,'sentiment.metadata' )\n",
        "sent_df.show(truncate = True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analyze_sentiment download started this may take some time.\n",
            "Approx size to download 4.9 MB\n",
            "[OK!]\n",
            "+--------------------+----------+--------------------+\n",
            "|                text|    result|            metadata|\n",
            "+--------------------+----------+--------------------+\n",
            "|could feel time w...|[positive]|[[confidence -> 0...|\n",
            "|take baby hold cl...|[positive]|[[confidence -> 0...|\n",
            "|come baby yeah co...|[positive]|[[confidence -> 0...|\n",
            "|day youll remembe...|[positive]|[[confidence -> 0...|\n",
            "|grudge slowly wet...|[positive]|[[confidence -> 0...|\n",
            "|donut talk listen...|[negative]|[[confidence -> 0...|\n",
            "|begin drift away ...|[positive]|[[confidence -> 0...|\n",
            "|aint need worry a...|[positive]|[[confidence -> 0...|\n",
            "|well leave mornin...|[positive]|[[confidence -> 0...|\n",
            "|music dennis drew...|[positive]|[[confidence -> 0...|\n",
            "|bend kneeive look...|[positive]|[[confidence -> 0...|\n",
            "|tung twista back ...|[positive]|[[confidence -> 0...|\n",
            "|bell toll sentenc...|[positive]|[[confidence -> 0...|\n",
            "|walk alone brick ...|[positive]|[[confidence -> 0...|\n",
            "|jenny jenny dont ...|[positive]|[[confidence -> 0...|\n",
            "|sad eye donut dis...|[positive]|[[confidence -> 0...|\n",
            "|look away western...|[positive]|[[confidence -> 0...|\n",
            "|make could ever m...|[positive]|[[confidence -> 0...|\n",
            "|im keeper heart k...|[negative]|[[confidence -> 0...|\n",
            "|leg maddox kitche...|[positive]|[[confidence -> 0...|\n",
            "+--------------------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgweVZdZ9QP0",
        "colab_type": "text"
      },
      "source": [
        "Save sentiment result and corresponding confidence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP5o6sSgB7GP",
        "colab_type": "text"
      },
      "source": [
        "1. find result and confidence column\n",
        "2. find top rows based on confidence and find top words for them using TF-IDF rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lRgGDa59T86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "01a46ea9-c641-414a-b49a-4b5b46eb3ebb"
      },
      "source": [
        "#convert list to sentence\n",
        "from pyspark.sql.functions import udf, explode\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "@udf(StringType())\n",
        "def get_result(sent_result):\n",
        "    result = sent_result[0]\n",
        "    return str(result)\n",
        "\n",
        "@udf(FloatType())\n",
        "def get_conf(sent_conf):\n",
        "    result = sent_conf[0]\n",
        "    conf = result.get('confidence')\n",
        "    return float(conf)\n",
        "\n",
        "df_sent_result = sent_df.select('text',get_result(F.col('result')).alias('result'),get_conf('metadata').alias('confidence') ) #\n",
        "df_sent_result.na.drop(subset=[\"confidence\"])\n",
        "df_sent_result.show()\n",
        "df_sent_result.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------+----------+\n",
            "|                text|  result|confidence|\n",
            "+--------------------+--------+----------+\n",
            "|could feel time w...|positive|    0.6221|\n",
            "|take baby hold cl...|positive|    0.8311|\n",
            "|come baby yeah co...|positive|    0.8025|\n",
            "|day youll remembe...|positive|    0.5757|\n",
            "|grudge slowly wet...|positive|    0.9414|\n",
            "|donut talk listen...|negative|    0.4813|\n",
            "|begin drift away ...|positive|    0.7405|\n",
            "|aint need worry a...|positive|    0.6867|\n",
            "|well leave mornin...|positive|    0.9522|\n",
            "|music dennis drew...|positive|    0.7857|\n",
            "|bend kneeive look...|positive|    0.8943|\n",
            "|tung twista back ...|positive|    0.7895|\n",
            "|bell toll sentenc...|positive|    0.6725|\n",
            "|walk alone brick ...|positive|    0.7489|\n",
            "|jenny jenny dont ...|positive|    0.5447|\n",
            "|sad eye donut dis...|positive|    0.8772|\n",
            "|look away western...|positive|    0.4822|\n",
            "|make could ever m...|positive|    0.8102|\n",
            "|im keeper heart k...|negative|    0.8324|\n",
            "|leg maddox kitche...|positive|    0.5447|\n",
            "+--------------------+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz353h1OO6ds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "cd7c968c-509a-49d9-f1e2-d5287f3b6e08"
      },
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, col\n",
        "\n",
        "window = Window.partitionBy(df_sent_result['result']).orderBy(df_sent_result['confidence'].desc())\n",
        "\n",
        "df_sent_result = df_sent_result.select('*', rank().over(window).alias('rank')).filter(col('rank') <= 50)\n",
        "df_sent_result.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------+----------+----+\n",
            "|                text|  result|confidence|rank|\n",
            "+--------------------+--------+----------+----+\n",
            "|tell lie deceitfu...|positive|     0.984|   1|\n",
            "|deep solace lie u...|positive|    0.9771|   2|\n",
            "|another awesome s...|positive|    0.9703|   3|\n",
            "|come everything o...|positive|    0.9546|   4|\n",
            "|love break apart ...|positive|    0.9539|   5|\n",
            "|well leave mornin...|positive|    0.9522|   6|\n",
            "|well leave mornin...|positive|    0.9522|   6|\n",
            "|grudge slowly wet...|positive|    0.9414|   8|\n",
            "|grudge slowly wet...|positive|    0.9414|   8|\n",
            "|ben sweller verse...|positive|    0.9388|  10|\n",
            "|letâs throw twili...|positive|    0.9285|  11|\n",
            "|wasnt restless fi...|positive|    0.9281|  12|\n",
            "|trocha fire go si...|positive|    0.9239|  13|\n",
            "|lucille please co...|positive|    0.9217|  14|\n",
            "|never know day li...|positive|    0.9107|  15|\n",
            "|fear fall hard li...|positive|    0.9096|  16|\n",
            "|fear fall hard li...|positive|    0.9096|  16|\n",
            "|dig u picture u e...|positive|    0.9089|  18|\n",
            "|lady keep doctor ...|positive|    0.9065|  19|\n",
            "|old forget crossw...|positive|    0.9036|  20|\n",
            "+--------------------+--------+----------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfbRkCW6X2yz",
        "colab_type": "text"
      },
      "source": [
        "### Top Positive word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEDZpe3DX_e2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "838360f2-8ff2-47c6-a6dd-9c08f9dcb0ef"
      },
      "source": [
        "df_positive = df_sent_result.filter(df_sent_result.result == 'positive')\n",
        "df_positive.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------+----------+----+\n",
            "|                text|  result|confidence|rank|\n",
            "+--------------------+--------+----------+----+\n",
            "|tell lie deceitfu...|positive|     0.984|   1|\n",
            "|deep solace lie u...|positive|    0.9771|   2|\n",
            "|another awesome s...|positive|    0.9703|   3|\n",
            "|come everything o...|positive|    0.9546|   4|\n",
            "|love break apart ...|positive|    0.9539|   5|\n",
            "|well leave mornin...|positive|    0.9522|   6|\n",
            "|well leave mornin...|positive|    0.9522|   6|\n",
            "|grudge slowly wet...|positive|    0.9414|   8|\n",
            "|grudge slowly wet...|positive|    0.9414|   8|\n",
            "|ben dweller verse...|positive|    0.9388|  10|\n",
            "|letâs throw twili...|positive|    0.9285|  11|\n",
            "|wasnt restless fi...|positive|    0.9281|  12|\n",
            "|trochi fire go si...|positive|    0.9239|  13|\n",
            "|lucille please co...|positive|    0.9217|  14|\n",
            "|never know day li...|positive|    0.9107|  15|\n",
            "|fear fall hard li...|positive|    0.9096|  16|\n",
            "|fear fall hard li...|positive|    0.9096|  16|\n",
            "|dig u picture u e...|positive|    0.9089|  18|\n",
            "|lady keep doctor ...|positive|    0.9065|  19|\n",
            "|old forget crossw...|positive|    0.9036|  20|\n",
            "+--------------------+--------+----------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_qiTpqhaJQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "a05595a2-5217-4535-d46a-e3798ca9e1d3"
      },
      "source": [
        "assembler = DocumentAssembler().setInputCol('text').setOutputCol('document')\n",
        "tokenizer = Tokenizer().setInputCols(['document']).setOutputCol('token')\n",
        "finisher = Finisher().setInputCols(['token']).setOutputCols(['text']).setOutputAsArray(True)\n",
        "\n",
        "pipeline_bow = Pipeline().setStages([\n",
        "    assembler, tokenizer, finisher\n",
        "])\n",
        "model_trans_tfIdf = pipeline_bow.fit(df_positive)\n",
        "top_positive =  model_trans_tfIdf.transform(df_positive)\n",
        "top_positive.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------+----------+----+\n",
            "|                text|  result|confidence|rank|\n",
            "+--------------------+--------+----------+----+\n",
            "|[tell, lie, decei...|positive|     0.984|   1|\n",
            "|[deep, solace, li...|positive|    0.9771|   2|\n",
            "|[another, awesome...|positive|    0.9703|   3|\n",
            "|[come, everything...|positive|    0.9546|   4|\n",
            "|[love, break, apa...|positive|    0.9539|   5|\n",
            "|[well, leave, mor...|positive|    0.9522|   6|\n",
            "|[well, leave, mor...|positive|    0.9522|   6|\n",
            "|[grudge, slowly, ...|positive|    0.9414|   8|\n",
            "|[grudge, slowly, ...|positive|    0.9414|   8|\n",
            "|[ben, dweller, ve...|positive|    0.9388|  10|\n",
            "|[letâs, throw, tw...|positive|    0.9285|  11|\n",
            "|[dasnt, restless,...|positive|    0.9281|  12|\n",
            "|[trucha, fire, go...|positive|    0.9239|  13|\n",
            "|[lucille, please,...|positive|    0.9217|  14|\n",
            "|[never, know, day...|positive|    0.9107|  15|\n",
            "|[fear, fall, hard...|positive|    0.9096|  16|\n",
            "|[fear, fall, hard...|positive|    0.9096|  16|\n",
            "|[dig, u, picture,...|positive|    0.9073|  18|\n",
            "|[lady, keep, doct...|positive|    0.9065|  19|\n",
            "|[old, forget, cro...|positive|    0.9036|  20|\n",
            "+--------------------+--------+----------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOJo6h_EeLSO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "b0d1127e-897b-4e02-ba48-fa39a381999f"
      },
      "source": [
        "from pyspark.ml.feature import CountVectorizer\n",
        "tfizer = CountVectorizer(inputCol='text', outputCol='tf_features')\n",
        "tf_model = tfizer.fit(top_positive)\n",
        "tf_result = tf_model.transform(top_positive)\n",
        "tf_result.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------+----------+----+--------------------+\n",
            "|                text|  result|confidence|rank|         tf_features|\n",
            "+--------------------+--------+----------+----+--------------------+\n",
            "|[tell, lie, decei...|positive|     0.984|   1|(1124,[0,32,37,38...|\n",
            "|[deep, solace, li...|positive|    0.9771|   2|(1124,[0,16,37,46...|\n",
            "|[another, awesome...|positive|    0.9703|   3|(1124,[7,11,23,27...|\n",
            "|[come, everything...|positive|    0.9546|   4|(1124,[0,5,6,7,11...|\n",
            "|[love, break, apa...|positive|    0.9539|   5|(1124,[0,3,55,57,...|\n",
            "|[well, leave, mor...|positive|    0.9522|   6|(1124,[0,7,15,23,...|\n",
            "|[well, leave, mor...|positive|    0.9522|   6|(1124,[0,7,15,23,...|\n",
            "|[grudge, slowly, ...|positive|    0.9414|   8|(1124,[1,6,28,65,...|\n",
            "|[grudge, slowly, ...|positive|    0.9414|   8|(1124,[1,6,28,65,...|\n",
            "|[ben, dweller, ve...|positive|    0.9388|  10|(1124,[0,10,11,17...|\n",
            "|[letâs, throw, tw...|positive|    0.9285|  11|(1124,[1,7,10,34,...|\n",
            "|[hasnt, restless,...|positive|    0.9281|  12|(1124,[0,1,3,5,8,...|\n",
            "|[troche, fire, go...|positive|    0.9239|  13|(1124,[21,25,140,...|\n",
            "|[lucille, please,...|positive|    0.9217|  14|(1124,[0,13,18,19...|\n",
            "|[never, know, day...|positive|    0.9107|  15|(1124,[0,1,2,10,1...|\n",
            "|[fear, fall, hard...|positive|    0.9096|  16|(1124,[0,1,3,4,10...|\n",
            "|[fear, fall, hard...|positive|    0.9096|  16|(1124,[0,1,3,4,10...|\n",
            "|[dig, u, picture,...|positive|    0.9089|  18|(1124,[1,5,8,10,1...|\n",
            "|[lady, keep, doct...|positive|    0.9065|  19|(1124,[0,1,3,5,11...|\n",
            "|[old, forget, cro...|positive|    0.9036|  20|(1124,[1,7,10,21,...|\n",
            "+--------------------+--------+----------+----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWx6kL4ieys2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "92654f6c-ae6d-4b53-963b-2f25606cd30a"
      },
      "source": [
        "from pyspark.ml.feature import IDF\n",
        "idfizer = IDF(inputCol='tf_features', \n",
        "              outputCol='tf_idf_features')\n",
        "idf_model = idfizer.fit(tf_result)\n",
        "tfidf_result = idf_model.transform(tf_result)\n",
        "tfidf_result.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------+----------+----+--------------------+--------------------+\n",
            "|                text|  result|confidence|rank|         tf_features|     tf_idf_features|\n",
            "+--------------------+--------+----------+----+--------------------+--------------------+\n",
            "|[tell, lie, decei...|positive|     0.984|   1|(1124,[0,32,37,38...|(1124,[0,32,37,38...|\n",
            "|[deep, solace, li...|positive|    0.9771|   2|(1124,[0,16,37,46...|(1124,[0,16,37,46...|\n",
            "|[another, awesome...|positive|    0.9703|   3|(1124,[7,11,23,27...|(1124,[7,11,23,27...|\n",
            "|[come, everything...|positive|    0.9546|   4|(1124,[0,5,6,7,11...|(1124,[0,5,6,7,11...|\n",
            "|[love, break, apa...|positive|    0.9539|   5|(1124,[0,3,55,57,...|(1124,[0,3,55,57,...|\n",
            "|[well, leave, mor...|positive|    0.9522|   6|(1124,[0,7,15,23,...|(1124,[0,7,15,23,...|\n",
            "|[well, leave, mor...|positive|    0.9522|   6|(1124,[0,7,15,23,...|(1124,[0,7,15,23,...|\n",
            "|[grudge, slowly, ...|positive|    0.9414|   8|(1124,[1,6,28,65,...|(1124,[1,6,28,65,...|\n",
            "|[grudge, slowly, ...|positive|    0.9414|   8|(1124,[1,6,28,65,...|(1124,[1,6,28,65,...|\n",
            "|[ben, sweller, ve...|positive|    0.9388|  10|(1124,[0,10,11,17...|(1124,[0,10,11,17...|\n",
            "|[letâs, throw, tw...|positive|    0.9285|  11|(1124,[1,7,10,34,...|(1124,[1,7,10,34,...|\n",
            "|[dasnt, restless,...|positive|    0.9281|  12|(1124,[0,1,3,5,8,...|(1124,[0,1,3,5,8,...|\n",
            "|[trucha, fire, go...|positive|    0.9239|  13|(1124,[21,25,140,...|(1124,[21,25,140,...|\n",
            "|[lucille, please,...|positive|    0.9217|  14|(1124,[0,13,18,19...|(1124,[0,13,18,19...|\n",
            "|[never, know, day...|positive|    0.9107|  15|(1124,[0,1,2,10,1...|(1124,[0,1,2,10,1...|\n",
            "|[fear, fall, hard...|positive|    0.9096|  16|(1124,[0,1,3,4,10...|(1124,[0,1,3,4,10...|\n",
            "|[fear, fall, hard...|positive|    0.9096|  16|(1124,[0,1,3,4,10...|(1124,[0,1,3,4,10...|\n",
            "|[dig, u, picture,...|positive|    0.9073|  18|(1124,[1,5,8,10,1...|(1124,[1,5,8,10,1...|\n",
            "|[lady, keep, doct...|positive|    0.9065|  19|(1124,[0,1,3,5,11...|(1124,[0,1,3,5,11...|\n",
            "|[old, forget, cro...|positive|    0.9036|  20|(1124,[1,7,10,21,...|(1124,[1,7,10,21,...|\n",
            "+--------------------+--------+----------+----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOuVZYbcfi8z",
        "colab_type": "text"
      },
      "source": [
        "lDA clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA7Brg6KfZde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.clustering import LDA\n",
        "num_topics = 6\n",
        "max_iter = 10\n",
        "lda = LDA(k=num_topics, \n",
        "          maxIter=max_iter, \n",
        "          featuresCol='tf_idf_features')\n",
        "lda_model = lda.fit(tfidf_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKqCr6ocfhgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "4c2aaf65-5350-4872-815d-8b394ea3aa47"
      },
      "source": [
        "vocab = tf_model.vocabulary\n",
        "@udf(ArrayType(StringType()))\n",
        "def get_words(token_list):\n",
        "    return [vocab[token_id] for token_id in token_list]\n",
        "\n",
        "num_top_words = 7\n",
        "topics = lda_model.describeTopics(num_top_words).withColumn('topicWords', get_words(F.col('termIndices')))\n",
        "topics.select('topic', 'topicWords').show(truncate=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------------------------------------------------------------+\n",
            "|topic|                                                   topicWords|\n",
            "+-----+-------------------------------------------------------------+\n",
            "|    0|[lucille, com, try, nothing, please, congratulations, inside]|\n",
            "|    1|          [attack, cease, sorrow, sit, attackshark, ooh, cry]|\n",
            "|    2|       [true, lucille, color, bone, searching, someone, take]|\n",
            "|    3|                   [know, need, world, true, color, susie, q]|\n",
            "|    4|                  [u, fancy, maybe, free, wed, whoever, bind]|\n",
            "|    5|                      [lose, donut, head, way, q, susie, say]|\n",
            "+-----+-------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx5enRmTYo3J",
        "colab_type": "text"
      },
      "source": [
        "### top Negative word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwMUv3QNYXiR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "abda2c84-3167-44e0-dbb3-20749eb8d9fb"
      },
      "source": [
        "df_negative = df_sent_result.filter(df_sent_result.result == 'negative')\n",
        "df_negative.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------+----------+----+\n",
            "|                text|  result|confidence|rank|\n",
            "+--------------------+--------+----------+----+\n",
            "|beyond boundary c...|positive|    0.5567|   1|\n",
            "|dont need educati...|negative|    0.9207|   1|\n",
            "|music john lombar...|negative|    0.8709|   2|\n",
            "|run say shore tak...|negative|    0.8573|   3|\n",
            "|se win zweig drei...|negative|    0.8363|   4|\n",
            "|im keeper heart k...|negative|    0.8324|   5|\n",
            "|engineer heavy he...|negative|    0.8229|   6|\n",
            "|look around tell ...|negative|    0.8096|   7|\n",
            "|dts ok go make mi...|negative|    0.8075|   8|\n",
            "|cat stevens ban l...|negative|     0.806|   9|\n",
            "|whoo yeah parent ...|negative|    0.8052|  10|\n",
            "|gretas cedar hope...|negative|    0.8041|  11|\n",
            "|want find somewhe...|negative|    0.8038|  12|\n",
            "|speak word plain ...|negative|    0.7946|  13|\n",
            "|lineage close dis...|negative|    0.7935|  14|\n",
            "|oath must break l...|negative|    0.7799|  15|\n",
            "|say goodbye troub...|negative|    0.7749|  16|\n",
            "|detroit laboston ...|negative|     0.772|  17|\n",
            "|yeah see go sex m...|negative|    0.7606|  18|\n",
            "|kid kid kid kid e...|negative|    0.7593|  19|\n",
            "+--------------------+--------+----------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnG2b6Avgdqk",
        "colab_type": "text"
      },
      "source": [
        "Perform same steps as for top positive words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nZSMBLvgqI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_wbyNMZrBu3",
        "colab_type": "text"
      },
      "source": [
        "# Supervised Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e7VOmr2rK9y",
        "colab_type": "text"
      },
      "source": [
        "peronsal Notes:\n",
        "Assume Repeat Calls as detractor calls and mark them as detractor calls; one with negative sentiment, we can also use range of repeat calls to define less negative, more negative sentiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0z-woGsrcu4",
        "colab_type": "text"
      },
      "source": [
        "Assuming rock contains more harsh word and negative content (this is just an assumption to showcase example of supervised sentiment analysis, you can create your own logic based on business needs) create label column and use SentimentDL to train your model"
      ]
    }
  ]
}